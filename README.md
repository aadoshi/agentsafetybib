# Safety Analysis and Control for AI Agents - Annotated Bibliography 
Author: Aarya Doshi, Carnegie Mellon University

## Context
...

## 1. Resources
Mislav Balunovic, Luca Beurer-Kellner, Marc Fischer, and Martin Vechev. 2024. [AI Agents with Formal Security Guarantees](https://openreview.net/forum?id=c6jNHPksiZ).

Luca Beurer-Kellner, Beat Buesser Ana-Maria Creţu, Edoardo Debenedetti, Daniel Dobos, Daniel Fabian, Marc Fischer, David Froelicher, Kathrin Grosse, Daniel Naeff, Ezinwanne Ozoani, Andrew Paverd, Florian Tramèr, and Václav Volhejn. 2025. [Design Patterns for Securing LLM Agents against Prompt Injections](https://doi.org/10.48550/arXiv.2506.08837). 

Manuel Costa, Boris Köpf, Aashish Kolluri, Andrew Paverd, Mark Russinovich, Ahmed Salem, Shruti Tople, Lukas Wutschitz, and Santiago Zanella-Béguelin. 2025. [Securing AI Agents with Information-Flow Control](https://doi.org/10.48550/arXiv.2505.23643). 

Edoardo Debenedetti, Ilia Shumailov, Tianqi Fan, Jamie Hayes, Nicholas Carlini, Daniel Fabian, Christoph Kern, Chongyang Shi, Andreas Terzis, and Florian Tramèr. 2025. [Defeating Prompt Injections by Design](https://doi.org/10.48550/arXiv.2503.18813). 

K. J. Kevin Feng, David W. McDonald, and Amy X. Zhang. 2025. [Levels of Autonomy for AI Agents](https://doi.org/10.48550/arXiv.2506.12469). 
Peter Yong Zhong, Siyuan Chen, Ruiqi Wang, McKenna McCall, Ben L. Titzer, Heather Miller, and Phillip B. Gibbons. 2025. [RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage](https://doi.org/10.48550/arXiv.2502.08966).
